"""
FindFlow YapÄ±landÄ±rma ModÃ¼lÃ¼
=======================================

Bu modÃ¼l, FindFlow uygulamasÄ±nÄ±n Gemini AI yapÄ±landÄ±rmasÄ± ve yardÄ±mcÄ± fonksiyonlarÄ±nÄ± iÃ§erir.SwipeStyle YapÄ±landÄ±rma ModÃ¼lÃ¼
==============================

Bu modÃ¼l, SwipeStyle uygulamasÄ±nÄ±n Gemini AI yapÄ±landÄ±rmasÄ± ve yardÄ±mcÄ± fonksiyonlarÄ±nÄ± iÃ§erir.
Gemini API'yi yapÄ±landÄ±rÄ±r, model nesnelerini oluÅŸturur ve retry mekanizmalarÄ± saÄŸlar.

Ana Fonksiyonlar:
- setup_gemini(): Gemini API'yi yapÄ±landÄ±rÄ±r
- get_gemini_model(): Optimize edilmiÅŸ Gemini modeli dÃ¶ner
- generate_with_retry(): Retry mekanizmasÄ± ile API istekleri gÃ¶nderir

Ã–zellikler:
- Otomatik API yapÄ±landÄ±rmasÄ±
- Optimize edilmiÅŸ model parametreleri
- Exponential backoff retry mekanizmasÄ±
- Hata yÃ¶netimi ve loglama

Gereksinimler:
- Google Generative AI (Gemini)
- .env dosyasÄ±nda GEMINI_API_KEY
- python-dotenv paketi
"""

import os
from dotenv import load_dotenv
import google.generativeai as genai
import time

def setup_gemini():
    """
    Gemini API'yi yapÄ±landÄ±rÄ±r ve baÅŸlatÄ±r - FindFlow iÃ§in optimize edilmiÅŸ.
    
    .env dosyasÄ±ndan API anahtarÄ±nÄ± okur ve Gemini API'yi yapÄ±landÄ±rÄ±r.
    BaÅŸarÄ±lÄ± yapÄ±landÄ±rma durumunda True, baÅŸarÄ±sÄ±z durumda False dÃ¶ner.
    
    Returns:
        bool: YapÄ±landÄ±rma baÅŸarÄ±lÄ± mÄ±?
        
    Ã–rnek:
        >>> if setup_gemini():
        ...     print("Gemini API baÅŸarÄ±yla yapÄ±landÄ±rÄ±ldÄ±")
        ... else:
        ...     print("Gemini API yapÄ±landÄ±rÄ±lamadÄ±")
    """
    load_dotenv()
    GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
    if GEMINI_API_KEY:
        genai.configure(api_key=GEMINI_API_KEY)
        return True
    return False

def get_gemini_model():
    """
    Optimize edilmiÅŸ Gemini modeli dÃ¶ner.
    
    FindFlow uygulamasÄ± iÃ§in Ã¶zel olarak yapÄ±landÄ±rÄ±lmÄ±ÅŸ
    Gemini modeli oluÅŸturur. SÄ±caklÄ±k, top_p, top_k ve
    max_output_tokens parametreleri optimize edilmiÅŸtir.
    
    Returns:
        genai.GenerativeModel: YapÄ±landÄ±rÄ±lmÄ±ÅŸ Gemini modeli
        
    Ã–rnek:
        >>> model = get_gemini_model()
        >>> response = model.generate_content("Merhaba")
    """
    # Relaxed safety settings to prevent empty responses
    safety_settings = [
        {
            "category": "HARM_CATEGORY_HARASSMENT",
            "threshold": "BLOCK_NONE"
        },
        {
            "category": "HARM_CATEGORY_HATE_SPEECH",
            "threshold": "BLOCK_NONE"
        },
        {
            "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
            "threshold": "BLOCK_NONE"
        },
        {
            "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
            "threshold": "BLOCK_NONE"
        }
    ]
    
    return genai.GenerativeModel(
        'gemini-1.5-flash',  # Daha yÃ¼ksek limit: 1000 req/min vs 10 req/min
        generation_config=genai.types.GenerationConfig(
            temperature=0.8,  # Increased for more creative responses
            top_p=0.95,      # Increased for more diverse responses
            top_k=40,        # Increased for more variety
            max_output_tokens=4096,  # Increased for longer responses
        ),
        safety_settings=safety_settings
    )

def generate_with_retry(model, prompt, max_retries=2, delay=10):
    """
    Gemini API'ye retry mekanizmasÄ± ile istek gÃ¶nderir.
    
    Bu fonksiyon, API isteklerini gÃ¼venilir hale getirmek iÃ§in
    exponential backoff retry mekanizmasÄ± kullanÄ±r. Her baÅŸarÄ±sÄ±z
    denemeden sonra bekleme sÃ¼resi artÄ±rÄ±lÄ±r.
    
    Args:
        model (genai.GenerativeModel): Gemini model nesnesi
        prompt (str): AI'ya gÃ¶nderilecek prompt metni
        max_retries (int): Maksimum deneme sayÄ±sÄ± (varsayÄ±lan: 3)
        delay (int): Ä°lk deneme arasÄ± bekleme sÃ¼resi (varsayÄ±lan: 2)
        
    Returns:
        genai.types.GenerateContentResponse or None: API yanÄ±tÄ± veya None
        
    Raises:
        Exception: TÃ¼m denemeler baÅŸarÄ±sÄ±z olduÄŸunda
        
    Ã–rnek:
        >>> model = get_gemini_model()
        >>> response = generate_with_retry(model, "Kategori Ã¶nerisi yap")
        >>> if response:
        ...     print(response.text)
    """
    for attempt in range(max_retries):
        try:
            print(f"ğŸ”„ Gemini API isteÄŸi (deneme {attempt + 1}/{max_retries})")
            response = model.generate_content(prompt)
            
            # Detailed response checking
            if response and hasattr(response, 'text') and response.text:
                print(f"âœ… Gemini API baÅŸarÄ±lÄ± (deneme {attempt + 1})")
                print(f"ğŸ“„ Response length: {len(response.text)} characters")
                return response
            elif response and hasattr(response, 'candidates') and response.candidates:
                # Check if response was blocked
                candidate = response.candidates[0]
                if hasattr(candidate, 'finish_reason'):
                    print(f"âš ï¸ Response blocked: {candidate.finish_reason} (deneme {attempt + 1})")
                    if hasattr(candidate, 'safety_ratings'):
                        print(f"ğŸ›¡ï¸ Safety ratings: {candidate.safety_ratings}")
                else:
                    print(f"âš ï¸ BoÅŸ yanÄ±t alÄ±ndÄ± (deneme {attempt + 1})")
            else:
                print(f"âš ï¸ GeÃ§ersiz response objesi (deneme {attempt + 1})")
                
        except Exception as e:
            print(f"âŒ Gemini API hatasÄ± (deneme {attempt + 1}): {e}")
            
        # Wait before retry (except on last attempt)
        if attempt < max_retries - 1:
            print(f"â³ {delay} saniye bekleniyor...")
            time.sleep(delay)
            delay *= 1.5  # Exponential backoff
    
    print(f"âŒ TÃ¼m denemeler baÅŸarÄ±sÄ±z oldu ({max_retries} deneme)")
    return None
